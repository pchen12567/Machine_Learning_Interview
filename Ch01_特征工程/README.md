# 第一章 特征工程
- 特征工程，顾名思义，是对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。
- 从本质上来讲，特征工程是一个表示和展现数据的过程。
- 在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关系。

两种常用的数据类型
- 结构化数据
    - 结构化数据类型可以看作关系型数据库的一张表，每列都有清晰的定义，包含了数值型、类别型两种基本类型；
    - 每一行数据表示一个样本的信息。
- 非结构化数据
    - 非结构化数据主要包括文本、图像、音频、视频数据，其包含的信息无法用一个简单的数值表示，也没有清晰的类别定义，并且每条数据的大小各不相同。
----
## 01 特征归一化 Normalization
- 为了消除数据特征之间的量纲影响，需要对特征进行归一化处理，使得不同指标之间具有可比性。
- 要想得到更为准确的结果，需要进行特征归一化处理，使各指标处于同一数值量级，以便进行分析。

### 为什么需要对数值类型的特征做归一化？
对数值类型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内
1. 线性函数归一化 Min-Max Scaling <br>
它对原始数据进行线性变换，使结果映射到[0,1]的范围，实现对原始数据的等比缩放，其公式如下: <br>
$$ X_{norm} = \cfrac{X - X_{min}}{X_{max} - X_{min}} $$

2. 零均值归一化 Z-Score Normalization <br>
它会将原始数据映射到均值为0、标准差为1的分布上。假设原始特征的均值为$\mu$、标准差为$\sigma$，那么其公式为: <br>
$$ z = \cfrac{x - \mu}{\sigma} $$

**数据归一化并不是万能的。** <br>
在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回归、支持向量机、神经网络等模型。<br>
但对于决策树模型则并不适用，因为信息增益比跟特征是否经过归一化是无关的，归一化并不会改变样本在特征X上的信息增益。

## 02 类别型特征 Categorical Feature
- 类别型特征主要是指性别、血型等只在有限选项内取值的特征。
- 类别型特征原始输入通常是字符串形式，除了决策树等少数模型外，类别型特性必须经过处理转换成数值型特征才能正确工作。

### 在对数据进行预处理时，应该怎样处理类别型特征？
1. 序号编码 <br>
通常用于处理类别间具有大小关系的数据，例如成绩可以分为低、中、高三档。

2. 独热编码 <br>
通常用于处理类别间不具有大小关系的特征，例如血型。
    - 使用稀疏向量来节省空间。
    - 配合特征选择来降低维度。
    
3. 二进制编码 <br>
    - 二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别，然后将类别ID对应的二进制编码作为结果。
    - 本质上是利用二进制对ID进行哈希映射，最终得到0/1特征向量，且维数小于独热编码，节省了存储空间。
![](https://github.com/pchen12567/picture_store/blob/master/Interview/feature_01.jpg?raw=true)

## 03 高维组合特征的处理
### 什么是组合特征？如何处理高维组合特征？
为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。

对于高维度组合特征 <br>
以用户ID和物品ID对点击的影响为例，若用户的数量为m，物品的数量为n，那么需要学习的参数规模为$$ m * n $$ <br>
一种行之有效的方法是将特征分别使用K维的低维向量表示，需要学习的参数的规模变为 $$m * k + n * k $$，这其实等价于矩阵分解。

## 04 组合特征



